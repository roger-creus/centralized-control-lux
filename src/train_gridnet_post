#!/bin/bash
#SBATCH --partition=long
#SBATCH --cpus-per-task=8
#SBATCH --gres=gpu:rtx8000:2                              
#SBATCH --mem=100G                                       
#SBATCH --time=168:00:00                                           
#SBATCH -o /network/scratch/r/roger.creus-castanyer/slurm-%j.out 

# 1. Load your environment
module load anaconda/3

export OMP_NUM_THREADS=1

#export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/

conda activate /home/mila/r/roger.creus-castanyer/anaconda3/envs/mario

# 4. Launch your job, tell it to save the model in $SLURM_TMPDIR
#    and look for the dataset into $SLURM_TMPDIR

torchrun --standalone --nnodes 1 --nproc_per_node 4 ppo_res_gridnet_multigpu.py --total-timesteps 1000000000 --clip-coef=0.14334778465053272 --ent-coef=0.002408486638907176 --gae-lambda=0.9322312137190516 --gamma=0.9945973988514306 --learning-rate=0.0016166261475302418 --max-grad-norm=0.28978755223510055 --minibatch-size=128 --num-envs=64 --num-steps=64 --pool-size=5 --save-every=75 --update-epochs=7 --vf-coef=0.2734614814048212 --device-ids 0 0 1 1
#wandb agent rogercreus/lux/w4eyctva

# 5. Copy whatever you want to save on $SCRATCH
cp -r $SLURM_TMPDIR/* /network/scratch/r/roger.creus-castanyer/